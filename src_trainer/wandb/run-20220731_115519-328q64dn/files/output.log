[2022-07-31 11:55:25,479 main.py:68 INFO]: loading data
[2022-07-31 11:55:25,480 tokenization_utils.py:938 INFO]: Model name 'hfl/chinese-roberta-wwm-ext' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'hfl/chinese-roberta-wwm-ext' is a path, a model identifier, or url to a directory containing tokenizer files.
[2022-07-31 11:55:26,755 tokenization_utils.py:1022 INFO]: loading file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/vocab.txt from cache at /home/v-zuangao/.cache/torch/transformers/5593eb652e3fb9a17042385245a61389ce6f0c8a25e167519477d7efbdf2459a.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[2022-07-31 11:55:26,755 tokenization_utils.py:1022 INFO]: loading file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/added_tokens.json from cache at /home/v-zuangao/.cache/torch/transformers/23740a16768d945f44a24590dc8f5e572773b1b2868c5e58f7ff4fae2a721c49.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2
[2022-07-31 11:55:26,756 tokenization_utils.py:1022 INFO]: loading file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/special_tokens_map.json from cache at /home/v-zuangao/.cache/torch/transformers/6f13f9fe28f96dd7be36b84708332115ef90b3b310918502c13a8f719a225de2.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4
[2022-07-31 11:55:26,756 tokenization_utils.py:1022 INFO]: loading file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/tokenizer_config.json from cache at /home/v-zuangao/.cache/torch/transformers/5bb5761fdb6c8f42bf7705c27c48cffd8b40afa8278fa035bc81bf288f108af9.1ade4e0ac224a06d83f2cb9821a6656b6b59974d6552e8c728f2657e4ba445d9
Building prefix dict from the default dictionary ...
[2022-07-31 11:57:34,437 __init__.py:113 DEBUG]: Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
[2022-07-31 11:57:34,438 __init__.py:133 DEBUG]: Loading model from cache /tmp/jieba.cache
Loading model cost 0.597 seconds.
[2022-07-31 11:57:35,035 __init__.py:165 DEBUG]: Loading model cost 0.597 seconds.
Prefix dict has been built successfully.
[2022-07-31 11:57:35,035 __init__.py:166 DEBUG]: Prefix dict has been built successfully.
TEXT: 4766, Image: 4766, label: 4766, Mask: 4766
TEXT: 1331, Image: 1331, label: 1331, Mask: 1331
[2022-07-31 12:00:26,074 main.py:75 INFO]: Train data_length => TEXT: 4766, Image: 4766, label: 4766, Mask: 4766
[2022-07-31 12:00:26,130 main.py:78 INFO]: Test data_length => TEXT: 1331, Image: 1331, label: 1331, Mask: 1331
[2022-07-31 12:00:26,130 main.py:90 INFO]: building model
[2022-07-31 12:00:27,315 configuration_utils.py:265 INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/config.json from cache at /home/v-zuangao/.cache/torch/transformers/3227a4c62d38cb0f891e7ccb8fc0b7b7dbd873889b3688c2e95834fb6f6109be.573c56a39f56f50b7bc6e9803d92871c74059419e37e87c5b14d49b1546b0703
[2022-07-31 12:00:27,317 configuration_utils.py:301 INFO]: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "directionality": "bidi",
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}
[2022-07-31 12:00:27,466 modeling_utils.py:650 INFO]: loading weights file https://cdn.huggingface.co/hfl/chinese-roberta-wwm-ext/pytorch_model.bin from cache at /home/v-zuangao/.cache/torch/transformers/47d2326d47246cef3121d70d592c0391a4ed594b04ce3dea8bd47edd37e20370.6ac27309c356295f0e005c6029fce503ec6a32853911ebf79f8bddd8dd10edad
[2022-07-31 12:00:28,713 main.py:92 INFO]: Multimodal_Net(
  (dropout): Dropout(p=0.5, inplace=False)
  (resnet): VGG(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace=True)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace=True)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace=True)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace=True)
      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (17): ReLU(inplace=True)
      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace=True)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace=True)
      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (24): ReLU(inplace=True)
      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (26): ReLU(inplace=True)
      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace=True)
      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (31): ReLU(inplace=True)
      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (33): ReLU(inplace=True)
      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (35): ReLU(inplace=True)
      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
    (classifier): Sequential(
      (0): Linear(in_features=25088, out_features=4096, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=True)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=1000, bias=True)
    )
  )
  (backbone): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace=True)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace=True)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace=True)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace=True)
      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (17): ReLU(inplace=True)
      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace=True)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace=True)
      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (24): ReLU(inplace=True)
      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (26): ReLU(inplace=True)
      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace=True)
      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (31): ReLU(inplace=True)
      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (33): ReLU(inplace=True)
      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (35): ReLU(inplace=True)
      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (roberta): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(21128, 768, padding_idx=1)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc_resnet): Linear(in_features=1000, out_features=32, bias=True)
  (fc_roberta): Linear(in_features=768, out_features=32, bias=True)
  (mult): MULTModel(
    (proj_l): Conv1d(768, 256, kernel_size=(1,), stride=(1,), bias=False)
    (proj_v): Conv1d(2048, 256, kernel_size=(1,), stride=(1,), bias=False)
    (trans_l_with_v): TransformerEncoder(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (trans_v_with_l): TransformerEncoder(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (trans_l_mem): TransformerEncoder(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (trans_v_mem): TransformerEncoder(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (layer_norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (proj1): Linear(in_features=512, out_features=512, bias=True)
    (proj2): Linear(in_features=512, out_features=512, bias=True)
    (proj3): Linear(in_features=256, out_features=32, bias=True)
    (out_layer): Linear(in_features=512, out_features=32, bias=True)
  )
  (embracenet): EmbraceNet(
    (docking_0): Linear(in_features=32, out_features=64, bias=True)
    (docking_1): Linear(in_features=32, out_features=64, bias=True)
  )
  (class_classifier): Sequential(
    (c_fc1): Linear(in_features=64, out_features=2, bias=True)
    (c_softmax): Softmax(dim=1)
  )
)
[2022-07-31 12:00:28,724 main.py:94 INFO]: expType: wo_fusion, train in expCode: wo_fusion_epoch50, batch_size 256, epoch = 50, lr = 0.0001
[2022-07-31 12:00:29,560 main.py:114 INFO]: start training model
[2022-07-31 12:00:57,830 main.py:190 INFO]: Epoch [1/50],  Loss: 0.6126, Class Loss: 0.6126, Train_Acc: 0.7034,  Validate_Acc: 0.8130.
[2022-07-31 12:01:26,912 main.py:190 INFO]: Epoch [2/50],  Loss: 0.4577, Class Loss: 0.4577, Train_Acc: 0.8853,  Validate_Acc: 0.8625.
[2022-07-31 12:01:56,268 main.py:190 INFO]: Epoch [3/50],  Loss: 0.3976, Class Loss: 0.3976, Train_Acc: 0.9227,  Validate_Acc: 0.8312.
[2022-07-31 12:02:24,400 main.py:190 INFO]: Epoch [4/50],  Loss: 0.3812, Class Loss: 0.3812, Train_Acc: 0.9348,  Validate_Acc: 0.9101.
[2022-07-31 12:02:55,405 main.py:190 INFO]: Epoch [5/50],  Loss: 0.3647, Class Loss: 0.3647, Train_Acc: 0.9505,  Validate_Acc: 0.8736.
[2022-07-31 12:03:23,671 main.py:190 INFO]: Epoch [6/50],  Loss: 0.3518, Class Loss: 0.3518, Train_Acc: 0.9626,  Validate_Acc: 0.8671.
[2022-07-31 12:03:52,140 main.py:190 INFO]: Epoch [7/50],  Loss: 0.3440, Class Loss: 0.3440, Train_Acc: 0.9709,  Validate_Acc: 0.8684.
[2022-07-31 12:04:20,607 main.py:190 INFO]: Epoch [8/50],  Loss: 0.3399, Class Loss: 0.3399, Train_Acc: 0.9748,  Validate_Acc: 0.8912.
[2022-07-31 12:04:49,197 main.py:190 INFO]: Epoch [9/50],  Loss: 0.3391, Class Loss: 0.3391, Train_Acc: 0.9747,  Validate_Acc: 0.9186.
[2022-07-31 12:05:18,847 main.py:190 INFO]: Epoch [10/50],  Loss: 0.3355, Class Loss: 0.3355, Train_Acc: 0.9784,  Validate_Acc: 0.8899.
[2022-07-31 12:05:47,380 main.py:190 INFO]: Epoch [11/50],  Loss: 0.3345, Class Loss: 0.3345, Train_Acc: 0.9793,  Validate_Acc: 0.9081.
[2022-07-31 12:06:15,945 main.py:190 INFO]: Epoch [12/50],  Loss: 0.3408, Class Loss: 0.3408, Train_Acc: 0.9716,  Validate_Acc: 0.8867.
[2022-07-31 12:06:44,524 main.py:190 INFO]: Epoch [13/50],  Loss: 0.3338, Class Loss: 0.3338, Train_Acc: 0.9802,  Validate_Acc: 0.8723.
[2022-07-31 12:07:13,119 main.py:190 INFO]: Epoch [14/50],  Loss: 0.3287, Class Loss: 0.3287, Train_Acc: 0.9845,  Validate_Acc: 0.8932.
[2022-07-31 12:07:41,687 main.py:190 INFO]: Epoch [15/50],  Loss: 0.3269, Class Loss: 0.3269, Train_Acc: 0.9864,  Validate_Acc: 0.8840.
[2022-07-31 12:08:10,296 main.py:190 INFO]: Epoch [16/50],  Loss: 0.3246, Class Loss: 0.3246, Train_Acc: 0.9894,  Validate_Acc: 0.8893.
[2022-07-31 12:08:38,917 main.py:190 INFO]: Epoch [17/50],  Loss: 0.3239, Class Loss: 0.3239, Train_Acc: 0.9895,  Validate_Acc: 0.8814.
[2022-07-31 12:09:07,505 main.py:190 INFO]: Epoch [18/50],  Loss: 0.3247, Class Loss: 0.3247, Train_Acc: 0.9886,  Validate_Acc: 0.8808.
[2022-07-31 12:09:36,079 main.py:190 INFO]: Epoch [19/50],  Loss: 0.3241, Class Loss: 0.3241, Train_Acc: 0.9897,  Validate_Acc: 0.9016.
[2022-07-31 12:10:04,723 main.py:190 INFO]: Epoch [20/50],  Loss: 0.3229, Class Loss: 0.3229, Train_Acc: 0.9908,  Validate_Acc: 0.8847.
[2022-07-31 12:10:33,329 main.py:190 INFO]: Epoch [21/50],  Loss: 0.3240, Class Loss: 0.3240, Train_Acc: 0.9895,  Validate_Acc: 0.8977.
[2022-07-31 12:11:01,925 main.py:190 INFO]: Epoch [22/50],  Loss: 0.3241, Class Loss: 0.3241, Train_Acc: 0.9893,  Validate_Acc: 0.8945.
[2022-07-31 12:11:30,602 main.py:190 INFO]: Epoch [23/50],  Loss: 0.3235, Class Loss: 0.3235, Train_Acc: 0.9901,  Validate_Acc: 0.8984.
[2022-07-31 12:11:59,194 main.py:190 INFO]: Epoch [24/50],  Loss: 0.3227, Class Loss: 0.3227, Train_Acc: 0.9904,  Validate_Acc: 0.8612.
[2022-07-31 12:12:27,951 main.py:190 INFO]: Epoch [25/50],  Loss: 0.3243, Class Loss: 0.3243, Train_Acc: 0.9888,  Validate_Acc: 0.8919.
[2022-07-31 12:12:56,582 main.py:190 INFO]: Epoch [26/50],  Loss: 0.3232, Class Loss: 0.3232, Train_Acc: 0.9901,  Validate_Acc: 0.9095.
[2022-07-31 12:13:25,233 main.py:190 INFO]: Epoch [27/50],  Loss: 0.3216, Class Loss: 0.3216, Train_Acc: 0.9916,  Validate_Acc: 0.9010.
[2022-07-31 12:13:53,921 main.py:190 INFO]: Epoch [28/50],  Loss: 0.3216, Class Loss: 0.3216, Train_Acc: 0.9918,  Validate_Acc: 0.9003.
[2022-07-31 12:14:22,470 main.py:190 INFO]: Epoch [29/50],  Loss: 0.3226, Class Loss: 0.3226, Train_Acc: 0.9906,  Validate_Acc: 0.8892.
[2022-07-31 12:14:51,020 main.py:190 INFO]: Epoch [30/50],  Loss: 0.3243, Class Loss: 0.3243, Train_Acc: 0.9888,  Validate_Acc: 0.8482.
[2022-07-31 12:15:19,505 main.py:190 INFO]: Epoch [31/50],  Loss: 0.3222, Class Loss: 0.3222, Train_Acc: 0.9912,  Validate_Acc: 0.8586.
[2022-07-31 12:15:47,971 main.py:190 INFO]: Epoch [32/50],  Loss: 0.3203, Class Loss: 0.3203, Train_Acc: 0.9930,  Validate_Acc: 0.8684.
[2022-07-31 12:16:16,547 main.py:190 INFO]: Epoch [33/50],  Loss: 0.3214, Class Loss: 0.3214, Train_Acc: 0.9921,  Validate_Acc: 0.8580.
[2022-07-31 12:16:45,116 main.py:190 INFO]: Epoch [34/50],  Loss: 0.3206, Class Loss: 0.3206, Train_Acc: 0.9928,  Validate_Acc: 0.9140.
[2022-07-31 12:17:13,689 main.py:190 INFO]: Epoch [35/50],  Loss: 0.3205, Class Loss: 0.3205, Train_Acc: 0.9928,  Validate_Acc: 0.9101.
[2022-07-31 12:17:42,282 main.py:190 INFO]: Epoch [36/50],  Loss: 0.3207, Class Loss: 0.3207, Train_Acc: 0.9926,  Validate_Acc: 0.9140.
[2022-07-31 12:18:10,893 main.py:190 INFO]: Epoch [37/50],  Loss: 0.3221, Class Loss: 0.3221, Train_Acc: 0.9912,  Validate_Acc: 0.8951.
[2022-07-31 12:18:39,504 main.py:190 INFO]: Epoch [38/50],  Loss: 0.3218, Class Loss: 0.3218, Train_Acc: 0.9916,  Validate_Acc: 0.8710.
[2022-07-31 12:19:08,100 main.py:190 INFO]: Epoch [39/50],  Loss: 0.3208, Class Loss: 0.3208, Train_Acc: 0.9924,  Validate_Acc: 0.8736.
[2022-07-31 12:19:36,692 main.py:190 INFO]: Epoch [40/50],  Loss: 0.3270, Class Loss: 0.3270, Train_Acc: 0.9858,  Validate_Acc: 0.9147.
[2022-07-31 12:20:05,243 main.py:190 INFO]: Epoch [41/50],  Loss: 0.3235, Class Loss: 0.3235, Train_Acc: 0.9898,  Validate_Acc: 0.8984.
[2022-07-31 12:20:33,706 main.py:190 INFO]: Epoch [42/50],  Loss: 0.3202, Class Loss: 0.3202, Train_Acc: 0.9931,  Validate_Acc: 0.8828.
[2022-07-31 12:21:02,131 main.py:190 INFO]: Epoch [43/50],  Loss: 0.3226, Class Loss: 0.3226, Train_Acc: 0.9909,  Validate_Acc: 0.8932.
[2022-07-31 12:21:30,591 main.py:190 INFO]: Epoch [44/50],  Loss: 0.3222, Class Loss: 0.3222, Train_Acc: 0.9905,  Validate_Acc: 0.8103.
[2022-07-31 12:21:59,176 main.py:190 INFO]: Epoch [45/50],  Loss: 0.3241, Class Loss: 0.3241, Train_Acc: 0.9890,  Validate_Acc: 0.8599.
[2022-07-31 12:22:27,756 main.py:190 INFO]: Epoch [46/50],  Loss: 0.3233, Class Loss: 0.3233, Train_Acc: 0.9894,  Validate_Acc: 0.8632.
[2022-07-31 12:22:56,350 main.py:190 INFO]: Epoch [47/50],  Loss: 0.3198, Class Loss: 0.3198, Train_Acc: 0.9935,  Validate_Acc: 0.8840.
[2022-07-31 12:23:24,951 main.py:190 INFO]: Epoch [48/50],  Loss: 0.3200, Class Loss: 0.3200, Train_Acc: 0.9931,  Validate_Acc: 0.8886.
[2022-07-31 12:23:53,543 main.py:190 INFO]: Epoch [49/50],  Loss: 0.3198, Class Loss: 0.3198, Train_Acc: 0.9932,  Validate_Acc: 0.9055.
[2022-07-31 12:24:22,261 main.py:190 INFO]: Epoch [50/50],  Loss: 0.3203, Class Loss: 0.3203, Train_Acc: 0.9930,  Validate_Acc: 0.9068.
[2022-07-31 12:24:22,262 main.py:201 INFO]: start testing model
[2022-07-31 12:24:23,513 configuration_utils.py:265 INFO]: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/hfl/chinese-roberta-wwm-ext/config.json from cache at /home/v-zuangao/.cache/torch/transformers/3227a4c62d38cb0f891e7ccb8fc0b7b7dbd873889b3688c2e95834fb6f6109be.573c56a39f56f50b7bc6e9803d92871c74059419e37e87c5b14d49b1546b0703
[2022-07-31 12:24:23,514 configuration_utils.py:301 INFO]: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "directionality": "bidi",
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}
[2022-07-31 12:24:23,620 modeling_utils.py:650 INFO]: loading weights file https://cdn.huggingface.co/hfl/chinese-roberta-wwm-ext/pytorch_model.bin from cache at /home/v-zuangao/.cache/torch/transformers/47d2326d47246cef3121d70d592c0391a4ed594b04ce3dea8bd47edd37e20370.6ac27309c356295f0e005c6029fce503ec6a32853911ebf79f8bddd8dd10edad
[2022-07-31 12:24:30,697 main.py:235 INFO]: Classification Acc: 0.9181, F1: 0.9181, Precision: 0.9182, Recall: 0.9185, AUC-ROC: 0.9701
[2022-07-31 12:24:30,703 main.py:237 INFO]: Classification report:
              precision    recall  f1-score   support
           0       0.90      0.93      0.92       648
           1       0.93      0.90      0.92       683
    accuracy                           0.92      1331
   macro avg       0.92      0.92      0.92      1331
weighted avg       0.92      0.92      0.92      1331
[2022-07-31 12:24:30,704 main.py:239 INFO]: Classification confusion matrix:
[[604  44]
 [ 65 618]]